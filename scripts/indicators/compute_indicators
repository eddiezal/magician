import os
import pandas as pd
import numpy as np
from google.cloud import bigquery
from pandas_gbq import to_gbq

# ðŸŒ BigQuery Configuration
PROJECT_ID = "cloud4marketing-281206"
DATASET_ID = "crypto_price"
RAW_TABLE = f"{PROJECT_ID}.{DATASET_ID}.coinbase_hourly_prices"
TECHNICALS_TABLE = f"{PROJECT_ID}.{DATASET_ID}.technical_indicators"

# ðŸ” Set authentication
CREDENTIALS_PATH = r"C:\Users\eddie\OneDrive\code\magician\config\cloud_credentials.json"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = CREDENTIALS_PATH
client = bigquery.Client()

# ðŸŸ¢ Step 1: Load Data from BigQuery (Last 6 Months for Freshness)
query = f"""
    SELECT asset, timestamp, open_price, high_price, low_price, close_price, volume
    FROM `{RAW_TABLE}`
    WHERE DATETIME(timestamp) >= DATETIME_SUB(CURRENT_DATETIME(), INTERVAL 6 MONTH)
    ORDER BY asset, timestamp
"""
df = client.query(query).to_dataframe()

# ðŸ” Debug: Check Unique Assets Before Processing
print(f"ðŸ” Unique assets count before processing: {df['asset'].nunique()}")
print(df['asset'].value_counts())  # See how many rows exist per asset
print(df[['asset', 'timestamp']].head(50))  # Sample data check

# ðŸ“ˆ Step 2: Compute Technical Indicators (Per Asset)
def compute_indicators(group):
    """Computes a set of technical indicators for each asset using Pandas & NumPy."""
    
    print(f"ðŸ› ï¸ Processing asset: {group['asset'].iloc[0]}, Rows: {len(group)}")  # Debug

    # ðŸ”¹ Moving Averages
    group["ema_20"] = group["close_price"].ewm(span=20, adjust=False).mean()
    group["ema_50"] = group["close_price"].ewm(span=50, adjust=False).mean()

    # ðŸ”¹ Relative Strength Index (RSI)
    delta = group["close_price"].diff()
    gain = np.where(delta > 0, delta, 0)
    loss = np.where(delta < 0, -delta, 0)
    avg_gain = pd.Series(gain).rolling(window=14, min_periods=1).mean()
    avg_loss = pd.Series(loss).rolling(window=14, min_periods=1).mean()
    rs = avg_gain / avg_loss
    group["rsi_14"] = 100 - (100 / (1 + rs))

    # ðŸ”¹ Bollinger Bands
    group["bollinger_mid"] = group["close_price"].rolling(window=20).mean()
    group["bollinger_std"] = group["close_price"].rolling(window=20).std()
    group["bollinger_upper"] = group["bollinger_mid"] + (group["bollinger_std"] * 2)
    group["bollinger_lower"] = group["bollinger_mid"] - (group["bollinger_std"] * 2)

    # ðŸ”¹ MACD
    short_ema = group["close_price"].ewm(span=12, adjust=False).mean()
    long_ema = group["close_price"].ewm(span=26, adjust=False).mean()
    group["macd"] = short_ema - long_ema
    group["macd_signal"] = group["macd"].ewm(span=9, adjust=False).mean()

    # ðŸ”¹ Money Flow Index (MFI)
    typical_price = (group["high_price"] + group["low_price"] + group["close_price"]) / 3
    money_flow = typical_price * group["volume"]
    pos_flow = money_flow.where(typical_price > typical_price.shift(), 0)
    neg_flow = money_flow.where(typical_price < typical_price.shift(), 0)
    money_ratio = pos_flow.rolling(14).sum() / neg_flow.rolling(14).sum()
    group["mfi_14"] = 100 - (100 / (1 + money_ratio))

    # ðŸ”¹ Z-Score (Mean Reversion)
    group["z_score"] = (group["close_price"] - group["close_price"].rolling(20).mean()) / group["close_price"].rolling(20).std()

    # ðŸ”¹ Average True Range (ATR)
    high_low = group["high_price"] - group["low_price"]
    high_close = np.abs(group["high_price"] - group["close_price"].shift())
    low_close = np.abs(group["low_price"] - group["close_price"].shift())

    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    group["atr_14"] = true_range.rolling(14).mean()

    return group

# ðŸ›  Apply Indicator Computation
df = df.groupby("asset", group_keys=True).apply(compute_indicators).reset_index(drop=True)

# ðŸ” Debug: Check Unique Assets After Processing
print(f"ðŸ” Unique assets count after processing: {df['asset'].nunique()}")
print(df['asset'].unique())  # List all unique asset names
print(df[['asset', 'timestamp']].head(50))  # Sample check

df.dropna(inplace=True)

# ðŸ›  Step 3: Upload Processed Data to BigQuery
to_gbq(df, TECHNICALS_TABLE, project_id=PROJECT_ID, if_exists="replace")

print("âœ… Technical indicators computed & uploaded to BigQuery!")
print([col for col in df.columns if 'atr' in col])
